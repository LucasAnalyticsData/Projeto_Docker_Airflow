# üöÄ Projeto de Orquestra√ß√£o de Dados com Apache Airflow & Docker

---

## üß≠ Vis√£o Geral do Projeto

Este projeto implementa um ambiente de orquestra√ß√£o de dados robusto e escal√°vel, utilizando **Apache Airflow 2.9.1** em um ecossistema **Docker**. A arquitetura foi desenhada para refletir um ambiente de produ√ß√£o, empregando as melhores pr√°ticas de Engenharia de Dados para garantir seguran√ßa, performance e reprodutibilidade.

O core da solu√ß√£o √© composto por:

-   üß© **Stack Principal**: Apache Airflow (Webserver, Scheduler, Worker, Triggerer) orquestrado via Docker Compose.
-   ‚öôÔ∏è **Executor Distribu√≠do**: `CeleryExecutor` para processamento de tarefas em paralelo, garantindo alta disponibilidade e escalabilidade horizontal.
-   üóÉÔ∏è **Metastore Confi√°vel**: **PostgreSQL 13** como banco de dados de metadados, desacoplado e persistente.
-   ‚ö° **Broker de Mensagens**: **Redis 7** como um broker leve e r√°pido para o Celery.
-   üîê **Seguran√ßa**: Execu√ß√£o de cont√™ineres com usu√°rio **n√£o-root** e gerenciamento de configura√ß√µes via vari√°veis de ambiente.
-   üîÑ **Inicializa√ß√£o Idempotente**: Um servi√ßo `airflow-init` garante que o banco de dados seja migrado e o usu√°rio administrador seja criado antes da inicializa√ß√£o dos servi√ßos principais, evitando condi√ß√µes de corrida.

---

## üó∫Ô∏è Arquitetura da Solu√ß√£o

O diagrama abaixo ilustra a intera√ß√£o entre os componentes da nossa stack de orquestra√ß√£o de dados:

```mermaid
graph TD
    A[Airflow Webserver] -->|L√™/Escreve metadados| B[(PostgreSQL 13)]
    C[Airflow Scheduler] -->|Agenda tarefas| D[(Redis 7 - Broker)]
    D --> E[Celery Workers]
    E -->|Executa tasks| B
    C -->|Persist√™ncia DAGs| B
    F[Triggerer] -->|Tarefas ass√≠ncronas| B
```

> **Por que o `CeleryExecutor` √© a escolha ideal aqui?** Diferente do `LocalExecutor`, ele permite que os `workers` (executores de tarefas) rodem em m√°quinas separadas, escalando a capacidade de processamento de forma independente do `scheduler` e do `webserver`. Isso √© fundamental para ambientes que processam um grande volume de dados ou que necessitam de alta disponibilidade.

---

## üåü Boas Pr√°ticas de Engenharia de Dados Aplicadas

| Pr√°tica | Implementa√ß√£o no Projeto | Justificativa T√©cnica (O "Porqu√™") |
| :--- | :--- | :--- |
| üöÄ **Executor Distribu√≠do** | `AIRFLOW__CORE__EXECUTOR=CeleryExecutor` | Permite a **escalabilidade horizontal** dos workers, isolando a execu√ß√£o das tarefas dos servi√ßos de agendamento e interface, o que aumenta a resili√™ncia e o throughput. |
| üóÉÔ∏è **Metastore Externo e Robusto** | PostgreSQL 13 configurado via `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN` | Garante a **confiabilidade e a consist√™ncia** dos metadados do Airflow, sendo a op√ß√£o recomendada para ambientes de produ√ß√£o em detrimento do SQLite. |
| ‚ö° **Broker de Mensagens Leve** | Redis 7 como broker para o Celery | Oferece uma **fila de mensagens r√°pida e de baixa lat√™ncia**, ideal para a comunica√ß√£o entre o scheduler e os workers do Celery. |
| üîÑ **Inicializa√ß√£o Idempotente** | Servi√ßo `airflow-init` com `db init` e `users create` | **Elimina condi√ß√µes de corrida** durante a inicializa√ß√£o, garantindo que o banco de dados esteja sempre migrado e pronto antes que os outros servi√ßos tentem se conectar. |
| ‚ù§Ô∏è **Healthchecks Inteligentes** | Uso de `/health`, `pg_isready`, `redis-cli ping`, `airflow jobs check` | Orquestra a **ordem de inicializa√ß√£o correta** dos cont√™ineres, facilita o diagn√≥stico de problemas e permite o autorreparo do ambiente. |
| üíæ **Persist√™ncia com Volumes Nomeados** | Logs, plugins e dados do DB em volumes Docker | **Desacopla o ciclo de vida dos dados** do ciclo de vida dos cont√™ineres, garantindo a persist√™ncia e melhorando a performance de I/O, especialmente no Docker Desktop (Windows/macOS). |
| üìÇ **Bind Mount Seletivo** | Apenas a pasta `dags/` √© montada via bind mount | Permite a **itera√ß√£o r√°pida no desenvolvimento de DAGs** (c√≥digo "vivo") sem a penalidade de performance de I/O que ocorreria se todos os arquivos do Airflow fossem montados via bind. |
| üîí **Princ√≠pio do Menor Privil√©gio** | Cont√™ineres rodam com usu√°rio n√£o-root (`user: "50000:0"`) | **Reduz a superf√≠cie de ataque** e evita problemas de permiss√£o de arquivos entre o host e os cont√™ineres. |
| üîë **Gerenciamento de Configura√ß√µes** | Centraliza√ß√£o de vari√°veis de ambiente em um arquivo `.env` | Alinha-se com a metodologia **12-Factor App**, mantendo as configura√ß√µes (que variam entre ambientes) separadas do c√≥digo e evitando que segredos sejam versionados. |
| üßπ **Higiene de Build e Parsing** | Uso de `.dockerignore`, `.gitignore` e `AIRFLOW__CORE__DAG_IGNORE_FILE_REGEX` | Resulta em **builds de imagem mais r√°pidos e leves**, e um `scheduler` mais eficiente, que n√£o perde tempo tentando parsear arquivos que n√£o s√£o DAGs. |

---

## üìÇ Estrutura do Projeto

```bash
üì¶ projeto_airflow/
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml      # Orquestra toda a stack de servi√ßos
‚îú‚îÄ‚îÄ üèóÔ∏è Dockerfile              # Define a imagem customizada (airflow-custom:latest)
‚îú‚îÄ‚îÄ üìã requirements.txt        # Depend√™ncias Python para as DAGs e plugins
‚îú‚îÄ‚îÄ ‚öôÔ∏è .env                    # Vari√°veis de ambiente (sens√≠veis ou espec√≠ficas do ambiente)
‚îú‚îÄ‚îÄ üö´ .dockerignore           # Arquivos a serem ignorados durante o build da imagem Docker
‚îú‚îÄ‚îÄ üö´ .gitignore              # Arquivos a serem ignorados pelo Git
‚îú‚îÄ‚îÄ  DAGs/
‚îÇ   ‚îú‚îÄ‚îÄ üìú etl_pipeline.py     # Exemplo de DAG de ETL
‚îÇ   ‚îú‚îÄ‚îÄ üìú airflow_v1_Aula1.py
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ Tipo_de_transacao.csv # Dado de entrada para a DAG
‚îî‚îÄ‚îÄ üîå plugins/                # Plugins customizados do Airflow (persistidos em volume)
```

> üí° **Otimiza√ß√£o de Performance:** O `scheduler` √© configurado para ignorar arquivos que n√£o s√£o DAGs, como notebooks Jupyter, checkpoints e caches do Python, atrav√©s da vari√°vel `AIRFLOW__CORE__DAG_IGNORE_FILE_REGEX`. Isso acelera o tempo de parsing e evita erros acidentais.

---

## ‚ñ∂Ô∏è Guia de Execu√ß√£o (Runbook)

O fluxo de inicializa√ß√£o do ambiente foi desenhado para ser sequencial e √† prova de falhas. Siga os passos abaixo:

```mermaid
sequenceDiagram
    participant U as üë®‚Äçüíª Usu√°rio
    participant D as üê≥ Docker
    participant I as üöÄ Airflow Init
    participant A as üåê Airflow UI

    U->>D: 1. `docker compose build`
    Note over D: Constr√≥i a imagem `airflow-custom:latest`
    D-->>U: Imagem constru√≠da com sucesso

    U->>D: 2. `docker compose up airflow-init`
    D->>I: Inicia o cont√™iner `airflow-init`
    I->>I: Executa `db init` e `users create`
    I-->>D: Cont√™iner finalizado com sucesso
    D-->>U: `airflow-init` conclu√≠do

    U->>D: 3. `docker compose up -d`
    Note over D: Inicia todos os outros servi√ßos (webserver, scheduler, etc.)
    D-->>U: Ambiente Airflow no ar!

    U->>A: 4. Acessa http://localhost:8080
    Note over A: Login: `airflow` / Senha: `airflow`
```

**Comandos para o Terminal:**

```bash
# 1. Construa a imagem customizada do Airflow
# Este comando l√™ o Dockerfile e o requirements.txt para criar a imagem com suas depend√™ncias.
docker compose build

# 2. Inicialize o banco de dados e crie o usu√°rio admin
# Este passo √© crucial e deve ser executado apenas uma vez por ambiente.
docker compose up airflow-init

# 3. Inicie todos os servi√ßos do Airflow em background
docker compose up -d

# 4. Acesse a UI do Airflow
# Abra seu navegador e acesse: http://localhost:8080 (login: airflow / senha: airflow)

# 5. Verifique o status dos cont√™ineres
docker compose ps

# 6. Acompanhe os logs de um servi√ßo espec√≠fico (ex: scheduler)
docker compose logs -f scheduler
```

---

## üß™ DAG de Exemplo: `etl_pipeline.py`

Esta DAG demonstra um pipeline de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) simples e robusto:

1.  **`load_file` (Extra√ß√£o)**: L√™ o arquivo `Tipo_de_transacao.csv`. Implementa uma l√≥gica de fallback para tentar diferentes delimitadores (`;` e `,`), tornando a extra√ß√£o mais resiliente a varia√ß√µes no formato do arquivo de entrada.
2.  **`transform_data` (Transforma√ß√£o)**: Renomeia colunas para nomes mais significativos (ex: `Tipo` para `Categoria`), filtra os dados para manter apenas as 10 categorias principais e salva o resultado em um novo arquivo CSV transformado.
3.  **`save_to_sqlite` (Carga)**: Carrega os dados transformados para uma tabela chamada `transacoes` em um banco de dados SQLite.

> **Por que o SQLite √© salvo em `/opt/airflow/logs/data`?**
> Esta pasta corresponde a um **volume nomeado do Docker**, e n√£o a um bind mount do sistema de arquivos do Windows. Isso **evita gargalos de I/O e problemas de permiss√£o** que s√£o comuns ao escrever arquivos a partir de cont√™ineres Docker no Windows.

**Como acessar o banco de dados SQLite gerado:**

```powershell
# Execute este comando no PowerShell, na raiz do seu projeto
docker compose cp webserver:/opt/airflow/logs/data/meu_banco.db .\saida_data\
```

---

## üß∞ Integra√ß√£o com Ferramentas de BI e Dados

### Conectando o DBeaver ao Metastore (PostgreSQL)

1.  No DBeaver, v√° em **Nova Conex√£o** e selecione **PostgreSQL**.
2.  Configure os par√¢metros da conex√£o:
    *   **Host**: `localhost`
    *   **Porta**: `5432`
    *   **Banco de Dados**: `airflow`
    *   **Usu√°rio**: `airflow`
    *   **Senha**: `airflow`
3.  Clique em **Testar Conex√£o** e, se tudo estiver correto, salve a conex√£o.

**Exemplos de Consultas SQL para An√°lise de Metadados:**

```sql
-- Listar todas as DAGs e seu status (pausada/ativa)
SELECT dag_id, is_paused, is_active, last_parsed_time
FROM dag
ORDER BY last_parsed_time DESC;

-- Analisar a performance de execu√ß√£o das DAGs
SELECT dag_id, COUNT(*) AS total_runs, AVG(EXTRACT(EPOCH FROM (end_date - start_date))) AS avg_duration_seconds
FROM dag_run
WHERE state = 'success'
GROUP BY dag_id
ORDER BY avg_duration_seconds DESC;
```

> üîí **Dica de Seguran√ßa para Produ√ß√£o:** Crie um usu√°rio **read-only** no PostgreSQL e use-o para as conex√µes de ferramentas de BI, garantindo que elas n√£o possam alterar os metadados do Airflow.

### Conectando o Power BI

#### Cen√°rio A: Conectar ao Metastore do Airflow (PostgreSQL)

1.  No Power BI, clique em **Obter Dados** e selecione **Banco de dados PostgreSQL**.
2.  Insira as informa√ß√µes do servidor:
    *   **Servidor**: `localhost`
    *   **Banco de dados**: `airflow`
3.  Use as credenciais `airflow` / `airflow`.
4.  Selecione as tabelas de metadados que deseja analisar, como `dag`, `dag_run`, `task_instance`, e `log`.
5.  Crie relat√≥rios para monitorar a sa√∫de do seu ambiente Airflow, como a taxa de sucesso de DAGs, o tempo m√©dio de execu√ß√£o e as tarefas que mais falham.

#### Cen√°rio B: Conectar ao Banco de Dados SQLite (sa√≠da da DAG) via ODBC

1.  **Instale o Driver ODBC do SQLite** para Windows (64-bit).
2.  Abra as **Fontes de Dados ODBC (64-bit)** no Windows e v√° para a aba **DSN de Sistema**.
3.  Clique em **Adicionar**, selecione o **SQLite3 ODBC Driver** e configure o DSN para apontar para o arquivo `meu_banco.db` que voc√™ copiou para a pasta `saida_data`.
4.  No Power BI, clique em **Obter Dados** e selecione **ODBC**. Escolha o DSN que voc√™ acabou de criar e importe a tabela `transacoes`.

> üîÑ **Mantenha seus dados atualizados:** Sempre que a DAG for reprocessada, execute novamente o comando `docker compose cp ...` e clique em **Atualizar** no Power BI para carregar os novos dados.

---

## ü©∫ Guia de Troubleshooting

-   **Erro de `mount` no Docker Desktop (Windows)**: `mkdir /run/desktop/mnt/host/c: file exists`
    *   **Causa**: Problemas de I/O com bind mounts no Windows.
    *   **Solu√ß√£o**: A arquitetura deste projeto j√° mitiga isso, usando bind mount **apenas para a pasta `dags/`** e volumes nomeados para todo o resto (logs, plugins, DB).

-   **Erro de encoding no arquivo `.env`**
    *   **Causa**: O arquivo `.env` foi salvo com uma codifica√ß√£o incorreta (ex: UTF-8 com BOM).
    *   **Solu√ß√£o**: Salve o arquivo `.env` com a codifica√ß√£o **UTF-8**. No VSCode, use a op√ß√£o *Salvar com Codifica√ß√£o*.

-   **Airflow continua pedindo `airflow db init`**
    *   **Causa**: O servi√ßo `airflow-init` n√£o foi executado ou falhou.
    *   **Solu√ß√£o**: Sempre siga o runbook: execute `docker compose up airflow-init` **antes** de `docker compose up -d`.

-   **Minha DAG n√£o aparece na UI**
    *   **Causa**: O arquivo da DAG n√£o est√° na pasta `dags/`, possui um erro de sintaxe, ou est√° sendo ignorado.
    *   **Solu√ß√£o**: Verifique o caminho do arquivo, a sintaxe Python e os logs do `scheduler` (`docker compose logs -f scheduler`) para encontrar erros de parsing.

---

## üèÅ Conclus√£o

Este projeto n√£o √© apenas uma configura√ß√£o funcional do Apache Airflow, mas uma demonstra√ß√£o de **dom√≠nio t√©cnico em Engenharia de Dados**. Ele evidencia a capacidade de construir pipelines de dados **seguros, escal√°veis e reprodut√≠veis**, utilizando as ferramentas e pr√°ticas mais modernas do mercado. A arquitetura foi pensada para ser resiliente e perform√°tica, pronta para desafios de orquestra√ß√£o de dados em ambientes complexos.


