# ğŸš€ Projeto de OrquestraÃ§Ã£o de Dados com Apache Airflow & Docker

---

## ğŸ§­ VisÃ£o Geral do Projeto

Este projeto implementa um ambiente de orquestraÃ§Ã£o de dados robusto e escalÃ¡vel, utilizando **Apache Airflow 2.9.1** em um ecossistema **Docker**. A arquitetura foi desenhada para refletir um ambiente de produÃ§Ã£o, empregando as melhores prÃ¡ticas de Engenharia de Dados para garantir seguranÃ§a, performance e reprodutibilidade.

O core da soluÃ§Ã£o Ã© composto por:

-   ğŸ§© **Stack Principal**: Apache Airflow (Webserver, Scheduler, Worker, Triggerer) orquestrado via Docker Compose.
-   âš™ï¸ **Executor DistribuÃ­do**: `CeleryExecutor` para processamento de tarefas em paralelo, garantindo alta disponibilidade e escalabilidade horizontal.
-   ğŸ—ƒï¸ **Metastore ConfiÃ¡vel**: **PostgreSQL 13** como banco de dados de metadados, desacoplado e persistente.
-   âš¡ **Broker de Mensagens**: **Redis 7** como um broker leve e rÃ¡pido para o Celery.
-   ğŸ” **SeguranÃ§a**: ExecuÃ§Ã£o de contÃªineres com usuÃ¡rio **nÃ£o-root** e gerenciamento de configuraÃ§Ãµes via variÃ¡veis de ambiente.
-   ğŸ”„ **InicializaÃ§Ã£o Idempotente**: Um serviÃ§o `airflow-init` garante que o banco de dados seja migrado e o usuÃ¡rio administrador seja criado antes da inicializaÃ§Ã£o dos serviÃ§os principais, evitando condiÃ§Ãµes de corrida.

---

## ğŸ—ºï¸ Arquitetura da SoluÃ§Ã£o

O diagrama abaixo ilustra a interaÃ§Ã£o entre os componentes da nossa stack de orquestraÃ§Ã£o de dados:

```mermaid
graph TD
    subgraph "Ambiente Docker"
        subgraph "ServiÃ§os Airflow"
            A[ğŸŒ Webserver] <--> C{CeleryExecutor}
            B[â° Scheduler] --> C
            C --> D[ğŸ‘· Celery Workers]
            F[âš¡ Triggerer] <--> C
        end

        subgraph "Infraestrutura de Suporte"
            G[ğŸ—ƒï¸ PostgreSQL Metastore] 
            H[âš¡ Redis Broker]
        end

        subgraph "Volumes Persistentes"
            I[ğŸ“‚ Volume de DAGs]
            J[ğŸ“„ Volume de Logs]
            K[ğŸ§© Volume de Plugins]
            L[ğŸ—„ï¸ Volume do Banco de Dados]
        end
    end

    subgraph "InteraÃ§Ã£o Externa"
        U[ğŸ‘¨â€ğŸ’» Engenheiro de Dados] --> I
        U --> A
        M[ğŸ› ï¸ DBeaver] --> G
        N[ğŸ“Š Power BI] --> G
        O[ğŸ“Š Power BI] --> P[SQLite SaÃ­da da DAG]
    end

    %% ConexÃµes
    A -- "LÃª/Escreve Metadados" --> G
    B -- "Envia Tarefas" --> H
    D -- "Consome Tarefas" --> H
    D -- "Executa Tarefas e Salva Resultados" --> G
    F -- "Gerencia Tarefas AssÃ­ncronas" --> G
    B -- "LÃª DefiniÃ§Ãµes de DAGs" --> I
    D -- "Gera Logs" --> J
    A -- "LÃª Logs" --> J
    C -- "Usa Plugins" --> K
    G -- "Persiste Dados" --> L
```

> **Por que o `CeleryExecutor` Ã© a escolha ideal aqui?** Diferente do `LocalExecutor`, ele permite que os `workers` (executores de tarefas) rodem em mÃ¡quinas separadas, escalando a capacidade de processamento de forma independente do `scheduler` e do `webserver`. Isso Ã© fundamental para ambientes que processam um grande volume de dados ou que necessitam de alta disponibilidade.

---

## ğŸŒŸ Boas PrÃ¡ticas de Engenharia de Dados Aplicadas

| PrÃ¡tica | ImplementaÃ§Ã£o no Projeto | Justificativa TÃ©cnica (O "PorquÃª") |
| :--- | :--- | :--- |
| ğŸš€ **Executor DistribuÃ­do** | `AIRFLOW__CORE__EXECUTOR=CeleryExecutor` | Permite a **escalabilidade horizontal** dos workers, isolando a execuÃ§Ã£o das tarefas dos serviÃ§os de agendamento e interface, o que aumenta a resiliÃªncia e o throughput. |
| ğŸ—ƒï¸ **Metastore Externo e Robusto** | PostgreSQL 13 configurado via `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN` | Garante a **confiabilidade e a consistÃªncia** dos metadados do Airflow, sendo a opÃ§Ã£o recomendada para ambientes de produÃ§Ã£o em detrimento do SQLite. |
| âš¡ **Broker de Mensagens Leve** | Redis 7 como broker para o Celery | Oferece uma **fila de mensagens rÃ¡pida e de baixa latÃªncia**, ideal para a comunicaÃ§Ã£o entre o scheduler e os workers do Celery. |
| ğŸ”„ **InicializaÃ§Ã£o Idempotente** | ServiÃ§o `airflow-init` com `db init` e `users create` | **Elimina condiÃ§Ãµes de corrida** durante a inicializaÃ§Ã£o, garantindo que o banco de dados esteja sempre migrado e pronto antes que os outros serviÃ§os tentem se conectar. |
| â¤ï¸ **Healthchecks Inteligentes** | Uso de `/health`, `pg_isready`, `redis-cli ping`, `airflow jobs check` | Orquestra a **ordem de inicializaÃ§Ã£o correta** dos contÃªineres, facilita o diagnÃ³stico de problemas e permite o autorreparo do ambiente. |
| ğŸ’¾ **PersistÃªncia com Volumes Nomeados** | Logs, plugins e dados do DB em volumes Docker | **Desacopla o ciclo de vida dos dados** do ciclo de vida dos contÃªineres, garantindo a persistÃªncia e melhorando a performance de I/O, especialmente no Docker Desktop (Windows/macOS). |
| ğŸ“‚ **Bind Mount Seletivo** | Apenas a pasta `dags/` Ã© montada via bind mount | Permite a **iteraÃ§Ã£o rÃ¡pida no desenvolvimento de DAGs** (cÃ³digo "vivo") sem a penalidade de performance de I/O que ocorreria se todos os arquivos do Airflow fossem montados via bind. |
| ğŸ”’ **PrincÃ­pio do Menor PrivilÃ©gio** | ContÃªineres rodam com usuÃ¡rio nÃ£o-root (`user: "50000:0"`) | **Reduz a superfÃ­cie de ataque** e evita problemas de permissÃ£o de arquivos entre o host e os contÃªineres. |
| ğŸ”‘ **Gerenciamento de ConfiguraÃ§Ãµes** | CentralizaÃ§Ã£o de variÃ¡veis de ambiente em um arquivo `.env` | Alinha-se com a metodologia **12-Factor App**, mantendo as configuraÃ§Ãµes (que variam entre ambientes) separadas do cÃ³digo e evitando que segredos sejam versionados. |
| ğŸ§¹ **Higiene de Build e Parsing** | Uso de `.dockerignore`, `.gitignore` e `AIRFLOW__CORE__DAG_IGNORE_FILE_REGEX` | Resulta em **builds de imagem mais rÃ¡pidos e leves**, e um `scheduler` mais eficiente, que nÃ£o perde tempo tentando parsear arquivos que nÃ£o sÃ£o DAGs. |

---

## ğŸ“‚ Estrutura do Projeto

```bash
ğŸ“¦ projeto_airflow/
â”œâ”€â”€ ğŸ³ docker-compose.yml      # Orquestra toda a stack de serviÃ§os
â”œâ”€â”€ ğŸ—ï¸ Dockerfile              # Define a imagem customizada (airflow-custom:latest)
â”œâ”€â”€ ğŸ“‹ requirements.txt        # DependÃªncias Python para as DAGs e plugins
â”œâ”€â”€ âš™ï¸ .env                    # VariÃ¡veis de ambiente (sensÃ­veis ou especÃ­ficas do ambiente)
â”œâ”€â”€ ğŸš« .dockerignore           # Arquivos a serem ignorados durante o build da imagem Docker
â”œâ”€â”€ ğŸš« .gitignore              # Arquivos a serem ignorados pelo Git
â”œâ”€â”€  DAGs/
â”‚   â”œâ”€â”€ ğŸ“œ etl_pipeline.py     # Exemplo de DAG de ETL
â”‚   â”œâ”€â”€ ğŸ“œ airflow_v1_Aula1.py
â”‚   â””â”€â”€ ğŸ“„ Tipo_de_transacao.csv # Dado de entrada para a DAG
â””â”€â”€ ğŸ”Œ plugins/                # Plugins customizados do Airflow (persistidos em volume)
```

> ğŸ’¡ **OtimizaÃ§Ã£o de Performance:** O `scheduler` Ã© configurado para ignorar arquivos que nÃ£o sÃ£o DAGs, como notebooks Jupyter, checkpoints e caches do Python, atravÃ©s da variÃ¡vel `AIRFLOW__CORE__DAG_IGNORE_FILE_REGEX`. Isso acelera o tempo de parsing e evita erros acidentais.

---

## â–¶ï¸ Guia de ExecuÃ§Ã£o (Runbook)

O fluxo de inicializaÃ§Ã£o do ambiente foi desenhado para ser sequencial e Ã  prova de falhas. Siga os passos abaixo:

```mermaid
sequenceDiagram
    participant U as ğŸ‘¨â€ğŸ’» UsuÃ¡rio
    participant D as ğŸ³ Docker
    participant I as ğŸš€ Airflow Init
    participant A as ğŸŒ Airflow UI

    U->>D: 1. `docker compose build`
    Note over D: ConstrÃ³i a imagem `airflow-custom:latest`
    D-->>U: Imagem construÃ­da com sucesso

    U->>D: 2. `docker compose up airflow-init`
    D->>I: Inicia o contÃªiner `airflow-init`
    I->>I: Executa `db init` e `users create`
    I-->>D: ContÃªiner finalizado com sucesso
    D-->>U: `airflow-init` concluÃ­do

    U->>D: 3. `docker compose up -d`
    Note over D: Inicia todos os outros serviÃ§os (webserver, scheduler, etc.)
    D-->>U: Ambiente Airflow no ar!

    U->>A: 4. Acessa http://localhost:8080
    Note over A: Login: `airflow` / Senha: `airflow`
```

**Comandos para o Terminal:**

```bash
# 1. Construa a imagem customizada do Airflow
# Este comando lÃª o Dockerfile e o requirements.txt para criar a imagem com suas dependÃªncias.
docker compose build

# 2. Inicialize o banco de dados e crie o usuÃ¡rio admin
# Este passo Ã© crucial e deve ser executado apenas uma vez por ambiente.
docker compose up airflow-init

# 3. Inicie todos os serviÃ§os do Airflow em background
docker compose up -d

# 4. Acesse a UI do Airflow
# Abra seu navegador e acesse: http://localhost:8080 (login: airflow / senha: airflow)

# 5. Verifique o status dos contÃªineres
docker compose ps

# 6. Acompanhe os logs de um serviÃ§o especÃ­fico (ex: scheduler)
docker compose logs -f scheduler
```

---

## ğŸ§ª DAG de Exemplo: `etl_pipeline.py`

Esta DAG demonstra um pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) simples e robusto:

1.  **`load_file` (ExtraÃ§Ã£o)**: LÃª o arquivo `Tipo_de_transacao.csv`. Implementa uma lÃ³gica de fallback para tentar diferentes delimitadores (`;` e `,`), tornando a extraÃ§Ã£o mais resiliente a variaÃ§Ãµes no formato do arquivo de entrada.
2.  **`transform_data` (TransformaÃ§Ã£o)**: Renomeia colunas para nomes mais significativos (ex: `Tipo` para `Categoria`), filtra os dados para manter apenas as 10 categorias principais e salva o resultado em um novo arquivo CSV transformado.
3.  **`save_to_sqlite` (Carga)**: Carrega os dados transformados para uma tabela chamada `transacoes` em um banco de dados SQLite.

> **Por que o SQLite Ã© salvo em `/opt/airflow/logs/data`?**
> Esta pasta corresponde a um **volume nomeado do Docker**, e nÃ£o a um bind mount do sistema de arquivos do Windows. Isso **evita gargalos de I/O e problemas de permissÃ£o** que sÃ£o comuns ao escrever arquivos a partir de contÃªineres Docker no Windows.

**Como acessar o banco de dados SQLite gerado:**

```powershell
# Execute este comando no PowerShell, na raiz do seu projeto
docker compose cp webserver:/opt/airflow/logs/data/meu_banco.db .\saida_data\
```

---

## ğŸ§° IntegraÃ§Ã£o com Ferramentas de BI e Dados

### Conectando o DBeaver ao Metastore (PostgreSQL)

1.  No DBeaver, vÃ¡ em **Nova ConexÃ£o** e selecione **PostgreSQL**.
2.  Configure os parÃ¢metros da conexÃ£o:
    *   **Host**: `localhost`
    *   **Porta**: `5432`
    *   **Banco de Dados**: `airflow`
    *   **UsuÃ¡rio**: `airflow`
    *   **Senha**: `airflow`
3.  Clique em **Testar ConexÃ£o** e, se tudo estiver correto, salve a conexÃ£o.

**Exemplos de Consultas SQL para AnÃ¡lise de Metadados:**

```sql
-- Listar todas as DAGs e seu status (pausada/ativa)
SELECT dag_id, is_paused, is_active, last_parsed_time
FROM dag
ORDER BY last_parsed_time DESC;

-- Analisar a performance de execuÃ§Ã£o das DAGs
SELECT dag_id, COUNT(*) AS total_runs, AVG(EXTRACT(EPOCH FROM (end_date - start_date))) AS avg_duration_seconds
FROM dag_run
WHERE state = 'success'
GROUP BY dag_id
ORDER BY avg_duration_seconds DESC;
```

> ğŸ”’ **Dica de SeguranÃ§a para ProduÃ§Ã£o:** Crie um usuÃ¡rio **read-only** no PostgreSQL e use-o para as conexÃµes de ferramentas de BI, garantindo que elas nÃ£o possam alterar os metadados do Airflow.

### Conectando o Power BI

#### CenÃ¡rio A: Conectar ao Metastore do Airflow (PostgreSQL)

1.  No Power BI, clique em **Obter Dados** e selecione **Banco de dados PostgreSQL**.
2.  Insira as informaÃ§Ãµes do servidor:
    *   **Servidor**: `localhost`
    *   **Banco de dados**: `airflow`
3.  Use as credenciais `airflow` / `airflow`.
4.  Selecione as tabelas de metadados que deseja analisar, como `dag`, `dag_run`, `task_instance`, e `log`.
5.  Crie relatÃ³rios para monitorar a saÃºde do seu ambiente Airflow, como a taxa de sucesso de DAGs, o tempo mÃ©dio de execuÃ§Ã£o e as tarefas que mais falham.

#### CenÃ¡rio B: Conectar ao Banco de Dados SQLite (saÃ­da da DAG) via ODBC

1.  **Instale o Driver ODBC do SQLite** para Windows (64-bit).
2.  Abra as **Fontes de Dados ODBC (64-bit)** no Windows e vÃ¡ para a aba **DSN de Sistema**.
3.  Clique em **Adicionar**, selecione o **SQLite3 ODBC Driver** e configure o DSN para apontar para o arquivo `meu_banco.db` que vocÃª copiou para a pasta `saida_data`.
4.  No Power BI, clique em **Obter Dados** e selecione **ODBC**. Escolha o DSN que vocÃª acabou de criar e importe a tabela `transacoes`.

> ğŸ”„ **Mantenha seus dados atualizados:** Sempre que a DAG for reprocessada, execute novamente o comando `docker compose cp ...` e clique em **Atualizar** no Power BI para carregar os novos dados.

---

## ğŸ©º Guia de Troubleshooting

-   **Erro de `mount` no Docker Desktop (Windows)**: `mkdir /run/desktop/mnt/host/c: file exists`
    *   **Causa**: Problemas de I/O com bind mounts no Windows.
    *   **SoluÃ§Ã£o**: A arquitetura deste projeto jÃ¡ mitiga isso, usando bind mount **apenas para a pasta `dags/`** e volumes nomeados para todo o resto (logs, plugins, DB).

-   **Erro de encoding no arquivo `.env`**
    *   **Causa**: O arquivo `.env` foi salvo com uma codificaÃ§Ã£o incorreta (ex: UTF-8 com BOM).
    *   **SoluÃ§Ã£o**: Salve o arquivo `.env` com a codificaÃ§Ã£o **UTF-8**. No VSCode, use a opÃ§Ã£o *Salvar com CodificaÃ§Ã£o*.

-   **Airflow continua pedindo `airflow db init`**
    *   **Causa**: O serviÃ§o `airflow-init` nÃ£o foi executado ou falhou.
    *   **SoluÃ§Ã£o**: Sempre siga o runbook: execute `docker compose up airflow-init` **antes** de `docker compose up -d`.

-   **Minha DAG nÃ£o aparece na UI**
    *   **Causa**: O arquivo da DAG nÃ£o estÃ¡ na pasta `dags/`, possui um erro de sintaxe, ou estÃ¡ sendo ignorado.
    *   **SoluÃ§Ã£o**: Verifique o caminho do arquivo, a sintaxe Python e os logs do `scheduler` (`docker compose logs -f scheduler`) para encontrar erros de parsing.

---

## ğŸ ConclusÃ£o

Este projeto nÃ£o Ã© apenas uma configuraÃ§Ã£o funcional do Apache Airflow, mas uma demonstraÃ§Ã£o de **domÃ­nio tÃ©cnico em Engenharia de Dados**. Ele evidencia a capacidade de construir pipelines de dados **seguros, escalÃ¡veis e reprodutÃ­veis**, utilizando as ferramentas e prÃ¡ticas mais modernas do mercado. A arquitetura foi pensada para ser resiliente e performÃ¡tica, pronta para desafios de orquestraÃ§Ã£o de dados em ambientes complexos.


